defaults:
  - pretrain_config
  - _self_

do_overwrite: false
seed: 1
retreiver_config:
  faiss_index_path: /mnt/shared_home/vlialin/documents/EventStreamGPT/data/faiss/faiss_index_14-32-52/faiss_index_14-32-52.idx
  documents_dir: /mnt/shared_home/vlialin/documents/EventStreamGPT/data/faiss/faiss_index_14-32-52
  embedder_name_or_path: roberta-large
  embedder_device: cuda:1
model_config:
  retreival_augmented: true
  chunked_cross_attention_chunk_len: 32
  retreived_states_hidden_size: 1024  # for roberta-large
  do_use_learnable_sinusoidal_ATE: false
  do_split_embeddings: false
  categorical_embedding_dim: null
  numerical_embedding_dim: null
  static_embedding_mode: sum_all
  static_embedding_weight: 0.5
  dynamic_embedding_weight: 0.5
  categorical_embedding_weight: 0.4
  numerical_embedding_weight: 0.5
  do_normalize_by_measurement_index: false
  structured_event_processing_mode: conditionally_independent
  num_hidden_layers: 12
  seq_attention_types:
  - global
  TTE_generation_layer_type: log_normal_mixture
  TTE_lognormal_generation_num_components: 8
  head_dim: 64
  hidden_size: 768
  num_attention_heads: 12
  attention_dropout: 0.1
  input_dropout: 0.1
  resid_dropout: 0.0
  intermediate_size: 3072
optimization_config:
  max_epochs: 100
  total_batch_size: 64
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  max_lr: 1e-3
  end_lr_frac_of_max_lr: 0.1
  end_lr: null
  lr_frac_warmup_steps: 0.05
  lr_decay_power: 1.0
  weight_decay: 0.1
  patience: 5
  num_dataloader_workers: 8
  eval_every: 10
  save_every: 10
  keep_last_n_checkpoints: 1
data_config:
  save_dir: /mnt/shared_home/vlialin/documents/EventStreamGPT/data/MIMIC_IV/ESD_06-13-23_150GB_10cpu-1
  max_seq_len: 192
  min_seq_len: 32
  pad_to_mutiple_of: 32  # should be a multiple of chunk length
  train_subset_size: FULL
  train_subset_seed: null
  task_df_name: null
  do_include_subsequence_indices: false
  do_include_subject_id: false
  do_include_start_time_min: false
pretraining_metrics_config:
  n_auc_thresholds: 50
  do_skip_all_metrics: false
  do_validate_args: false
  include_metrics:
    train:
      LOSS_PARTS: true
final_validation_metrics_config:
  n_auc_thresholds: 25
  do_skip_all_metrics: false
  do_validate_args: false
  include_metrics:
    TUNING:
      LOSS_PARTS: true
      TTE:
        MSE: true
        MSLE: true
      CLASSIFICATION:
        AUROC:
        - WEIGHTED
        ACCURACY: true
      REGRESSION:
        MSE: true
    HELD_OUT:
      LOSS_PARTS: true
      TTE:
        MSE: true
        MSLE: true
      CLASSIFICATION:
        AUROC:
        - WEIGHTED
        ACCURACY: true
      REGRESSION:
        MSE: true
experiment_dir: models/${now:%Y-%m-%d_%H-%M-%S}
wandb_logger_kwargs:
  project: MIMIC_FMs_public
do_final_validation_on_metrics: true
